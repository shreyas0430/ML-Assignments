{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math \n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset : \n",
      "\n",
      "[[8.450e+03 7.000e+00 5.000e+00 ... 0.000e+00 5.480e+02 1.000e+00]\n",
      " [9.600e+03 6.000e+00 8.000e+00 ... 1.000e+00 4.600e+02 1.000e+00]\n",
      " [1.125e+04 7.000e+00 5.000e+00 ... 1.000e+00 6.080e+02 1.000e+00]\n",
      " ...\n",
      " [9.042e+03 7.000e+00 9.000e+00 ... 2.000e+00 2.520e+02 1.000e+00]\n",
      " [9.717e+03 5.000e+00 6.000e+00 ... 0.000e+00 2.400e+02 0.000e+00]\n",
      " [9.937e+03 5.000e+00 6.000e+00 ... 0.000e+00 2.760e+02 0.000e+00]]\n",
      "\n",
      "Dimensions of dataset : (1460, 11)\n"
     ]
    }
   ],
   "source": [
    "data_orig = np.genfromtxt('a2_data/housepricedata.csv',delimiter=',',skip_header=1)\n",
    "print(\"Dataset : \\n\\n\"+ str(data_orig))\n",
    "print(\"\\nDimensions of dataset : \"+str(data_orig.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output Y   :[1. 1. 1. ... 1. 0. 0.]\n",
      "Shape of Y : (1460,)\n"
     ]
    }
   ],
   "source": [
    "#Extacting Y\n",
    "y_orig = data_orig[:,-1]\n",
    "print(\"Output Y   :\"+str(y_orig))\n",
    "print(\"Shape of Y : \"+str(y_orig.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Y: (1, 1460)\n",
      "49.86301369863014\n"
     ]
    }
   ],
   "source": [
    "#Removing Rank 1 array\n",
    "Y = np.reshape(y_orig,(y_orig.shape[0],1)).T    \n",
    "print(\"Shape of Y: \"+ str(Y.shape))\n",
    "print((np.sum(Y)/1460)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 1460)\n"
     ]
    }
   ],
   "source": [
    "#Extracting vectorized input feature X (transposed)\n",
    "X = data_orig[:,0:-1].T\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize(x):\n",
    "    x_mean = np.mean(x,axis=1, keepdims=True)\n",
    "    x_std = np.std(x, axis=1, keepdims=True)+0.0000001\n",
    "\n",
    "    X = (x - x_mean)/x_std   #Python Broadcasting\n",
    "\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = standardize(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Shape of Training set X : (10, 1168)\n",
      "Shape of Training set Y : (1, 1168)\n",
      "\n",
      "Shape of Test set   X   : (10, 292)\n",
      "Shape of Test set Y     : (1, 292)\n"
     ]
    }
   ],
   "source": [
    "#Splitting into Train, Test sets ( with a fixed seed )\n",
    "train_split_percent = 80\n",
    "test_split_percent = 20\n",
    "\n",
    "train_X , test_X = X[:, : int( (train_split_percent/100)*X.shape[1])] , X[:,int( (train_split_percent/100)*X.shape[1]) : ]\n",
    "train_Y , test_Y = Y[:, : int( (train_split_percent/100)*X.shape[1])] , Y[:,int( (train_split_percent/100)*X.shape[1]) : ]\n",
    "print(\"\\nShape of Training set X : \"+str(train_X.shape))\n",
    "print(\"Shape of Training set Y : \"+str(train_Y.shape))\n",
    "print(\"\\nShape of Test set   X   : \"+str(test_X.shape))\n",
    "print(\"Shape of Test set Y     : \"+str(test_Y.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of training examples : 1168\n",
      "No of test example      : 292\n",
      "50.0\n"
     ]
    }
   ],
   "source": [
    "m_train = train_X.shape[1]\n",
    "m_test  = test_X.shape[1]\n",
    "print(\"No of training examples : \"+str(m_train))\n",
    "print(\"No of test example      : \"+str(m_test))\n",
    "print((np.sum(1-test_Y)/292)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(Z):\n",
    "    sigz= 1/(1+np.exp(-Z))\n",
    "    sigz[sigz==1] = 0.99999999999             #Incase of flow\n",
    "    sigz[sigz==0] = 0.000000000001\n",
    "    return sigz        \n",
    "\n",
    "def relu(Z):\n",
    "    return np.maximum(0,Z)\n",
    "\n",
    "def sigmoid_backward(dA, Z):\n",
    "    sig = sigmoid(Z)\n",
    "    return dA * sig * (1 - sig)\n",
    "\n",
    "def relu_backward(dA, Z):\n",
    "    dZ = np.array(dA, copy = True)\n",
    "    dZ[Z <= 0] = 0;\n",
    "    return dZ;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_parameters(n_x, n_h, n_y):\n",
    "    \n",
    "    W1 = np.random.randn(n_h,n_x)*0.1\n",
    "    b1 = np.zeros((n_h,1))\n",
    "    W2 = np.random.randn(n_y,n_h)*0.1\n",
    "    b2 = np.zeros((n_y,1))\n",
    "    \n",
    "    p = {\"W1\": W1,\"b1\": b1,   \"W2\": W2, \"b2\": b2}\n",
    "    \n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_parameters_deep(layers):\n",
    "    p = {}\n",
    "    L = len(layers)            \n",
    "\n",
    "    for l in range(1, L):\n",
    "        p['W' + str(l)] = np.random.randn(layers[l],layers[l-1])*(2/layers[l-1])**0.5\n",
    "        p['b' + str(l)] = np.zeros((layers[l],1))\n",
    "        \n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_forward(A, W, b):\n",
    "   \n",
    "    Z = np.dot(W,A)+b\n",
    "    #Z = standardize(Z) Batch-Normalize with u,var=1\n",
    "    cache = (A, W, b)\n",
    "    \n",
    "    return Z, cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_activation_forward(A_prev, W, b, activation,layer):\n",
    "    \n",
    "    if activation == \"sigmoid\":\n",
    "        Z, linear_cache = linear_forward(A_prev,W,b)\n",
    "        A, activation_cache = sigmoid(Z), sigmoid(Z)\n",
    "    \n",
    "    elif activation == \"relu\":\n",
    "        Z, linear_cache = linear_forward(A_prev,W,b)\n",
    "        A, activation_cache = relu(Z), relu(Z)\n",
    "        dropout_cache = A\n",
    "        D = np.random.rand(A.shape[0],A.shape[1]) \n",
    "        if layer==1:\n",
    "            D[:,:]=1\n",
    "        else:\n",
    "            D = (D < keep_prob).astype(int)                                         \n",
    "            A = A*D                                         \n",
    "            A = A/keep_prob \n",
    "        global Dcache \n",
    "        Dcache = D\n",
    "    \n",
    "    cache = (linear_cache, activation_cache,Dcache)\n",
    "\n",
    "    return A, cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forwardprop(X, p):\n",
    "\n",
    "    caches = []\n",
    "    D = []\n",
    "    A = X\n",
    "    L = len(p) // 2                \n",
    "    \n",
    "    for l in range(1, L):\n",
    "        A_prev = A \n",
    "        A, cache = linear_activation_forward(A_prev, p[\"W\"+str(l)], p[\"b\"+str(l)],\"relu\",l)\n",
    "        caches.append(cache)\n",
    "        \n",
    "    AL, cache = linear_activation_forward(A, p[\"W\"+str(L)], p[\"b\"+str(L)],\"sigmoid\",l)\n",
    "    caches.append(cache)\n",
    "            \n",
    "    return AL, caches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cost(AL, Y,p):\n",
    "    \n",
    "    m = Y.shape[1]\n",
    "    #print(AL)\n",
    "    cost = (-1/m)*(np.sum(Y*np.log(AL)+(1-Y)*np.log(1-AL)))\n",
    "    sumW = 0\n",
    "    L = len(p) // 2 \n",
    "    for l in range(1, L):\n",
    "        sumW= sumW + np.sum(np.square(p[\"W\"+str(l)]))\n",
    "        \n",
    "    L2_cost= lambd*(sumW)/(2*m)\n",
    "    cost = cost + L2_cost\n",
    "    cost = np.squeeze(cost)     \n",
    "   \n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_backward(dZ, linear_cache,keep_prob):\n",
    "    \n",
    "    A_prev, W, b = linear_cache\n",
    "    m = A_prev.shape[1]\n",
    "\n",
    "    dW = (1/m)*np.dot(dZ,A_prev.T)\n",
    "    db = (1/m)*np.sum(dZ,axis=1,keepdims=True)\n",
    "    dA_prev = np.dot(W.T,dZ)\n",
    "    \n",
    "    return dA_prev, dW, db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_activation_backward(dA, cache, activation,keep_prob):\n",
    "\n",
    "    linear_cache, activation_cache, dropout_cache = cache\n",
    "    global dA_prev, dW, db\n",
    "    if activation == \"relu\":\n",
    "        dZ = relu_backward(dA,activation_cache)\n",
    "        dA_prev, dW, db = linear_backward(dZ, linear_cache,keep_prob)\n",
    "        \n",
    "    elif activation == \"sigmoid\":\n",
    "        dZ = sigmoid_backward(dA,activation_cache)\n",
    "        dA_prev, dW, db = linear_backward(dZ, linear_cache,keep_prob=1)\n",
    "    \n",
    "    return dA_prev, dW, db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backwardprop(AL, Y, caches):\n",
    "    grads = {}\n",
    "    L = len(caches) \n",
    "    m = AL.shape[1]\n",
    "    Y = Y.reshape(AL.shape) \n",
    "    \n",
    "    dAL = - (np.divide(Y, AL) - np.divide(1 - Y, 1 - AL))\n",
    "    \n",
    "    #print(caches[-2][-1].shape)\n",
    "    #print(L)\n",
    "    \n",
    "    current_cache = caches[-1]\n",
    "    grads[\"dA\" + str(L-1)], grads[\"dW\" + str(L)], grads[\"db\" + str(L)] = linear_activation_backward(dAL, current_cache,\"sigmoid\",keep_prob=1)\n",
    "    \n",
    "    for l in reversed(range(L-1)):\n",
    "        current_cache = caches[l]\n",
    "        global Dprev_cache\n",
    "        D_prev = caches[l-1][2]\n",
    "        global dA_prev_temp, dW_temp, db_temp\n",
    "        dA_prev_temp, dW_temp, db_temp = linear_activation_backward(grads[\"dA\" + str(l + 1)], current_cache,\n",
    "                                                                \"relu\",keep_prob)\n",
    "        if l > 0:\n",
    "            dA_prev_temp = np.multiply(dA_prev_temp,D_prev)\n",
    "            dA_prev_temp = dA_prev_temp/keep_prob\n",
    "        grads[\"dA\" + str(l)] = dA_prev_temp\n",
    "        grads[\"dW\" + str(l + 1)] = dW_temp\n",
    "        grads[\"db\" + str(l + 1)] = db_temp\n",
    "\n",
    "    return grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_adam(p) :\n",
    "\n",
    "    L = len(p) // 2 \n",
    "    v = {}\n",
    "    s = {}\n",
    "    \n",
    "    for l in range(L):\n",
    "        v[\"dW\" + str(l+1)] = np.zeros((p[\"W\" + str(l+1)].shape[0],p[\"W\" + str(l+1)].shape[1]))\n",
    "        v[\"db\" + str(l+1)] = np.zeros((p[\"b\" + str(l+1)].shape[0],p[\"b\" + str(l+1)].shape[1]))\n",
    "        s[\"dW\" + str(l+1)] = np.zeros((p[\"W\" + str(l+1)].shape[0],p[\"W\" + str(l+1)].shape[1]))\n",
    "        s[\"db\" + str(l+1)] = np.zeros((p[\"b\" + str(l+1)].shape[0],p[\"b\" + str(l+1)].shape[1]))\n",
    "   \n",
    "    return v, s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Adam_optimizer(p, g, v, s, t,m, learning_rate = 0.01,\n",
    "                                beta1 = 0.9, beta2 = 0.999,  epsilon = 1e-8,):\n",
    "\n",
    "    L = len(p) // 2                 \n",
    "    v_corrected = {}                         \n",
    "    s_corrected = {}                        \n",
    "    \n",
    "    # Perform Adam update on all parameters\n",
    "    for l in range(L):\n",
    "        v[\"dW\" + str(l+1)] = beta1*v[\"dW\" + str(l+1)]+(1-beta1)*g['dW'+str(l+1)]\n",
    "        v[\"db\" + str(l+1)] = beta1*v[\"db\" + str(l+1)]+(1-beta1)*g['db'+str(l+1)]\n",
    "       \n",
    "        v_corrected[\"dW\" + str(l+1)] = v[\"dW\" + str(l+1)]/(1-pow(beta1,t)) \n",
    "        v_corrected[\"db\" + str(l+1)] = v[\"db\" + str(l+1)]/(1-pow(beta1,t))\n",
    "        \n",
    "        s[\"dW\" + str(l+1)] = beta2*s[\"dW\" + str(l+1)]+(1-beta2)*np.power(g['dW'+str(l+1)],2)\n",
    "        s[\"db\" + str(l+1)] = beta2*s[\"db\" + str(l+1)]+(1-beta2)*np.power(g['db'+str(l+1)],2)\n",
    "\n",
    "        s_corrected[\"dW\" + str(l+1)] = s[\"dW\" + str(l+1)]/(1-pow(beta2,t))\n",
    "        s_corrected[\"db\" + str(l+1)] = s[\"db\" + str(l+1)]/(1-pow(beta2,t))\n",
    "\n",
    "        p[\"W\" + str(l+1)] = p[\"W\" + str(l+1)]-learning_rate*np.divide(v_corrected[\"dW\" + str(l+1)],np.sqrt(s_corrected[\"dW\" + str(l+1)])+epsilon)\n",
    "        p[\"W\" + str(l+1)] = p[\"W\"+ str(l+1)] +(lambd/m)*p[\"W\" + str(l+1)]\n",
    "        p[\"b\" + str(l+1)] = p[\"b\" + str(l+1)]-learning_rate*np.divide(v_corrected[\"db\" + str(l+1)],np.sqrt(s_corrected[\"db\" + str(l+1)])+epsilon)\n",
    "\n",
    "    return p, v, s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(X, Y, layers_dims, learning_rate0 = 0.003, epocs = 3000,\n",
    "                  beta1 = 0.9, beta2 = 0.999,  epsilon = 1e-8, print_after=1):\n",
    "\n",
    "    costs = []                      \n",
    "    \n",
    "    parameters = initialize_parameters_deep(layers_dims)\n",
    "    v, s = initialize_adam(parameters)\n",
    "    \n",
    "    t = 0\n",
    "    m=X.shape[1]\n",
    "    \n",
    "    for i in range(0, epocs):\n",
    "        AL, caches = forwardprop(X, parameters)\n",
    "        cost = compute_cost(AL, Y,parameters)\n",
    "        grads = backwardprop(AL, Y, caches)\n",
    "        \n",
    "        t = t + 1\n",
    "        learning_rate = learning_rate0/(1+decay_rate*i)\n",
    "        \n",
    "        parameters, v, s = Adam_optimizer(parameters, grads, v, s,\n",
    "                                                               t,m, learning_rate, beta1, beta2,  epsilon,)\n",
    "        if i % print_after == 0:\n",
    "            print (\"Cost after iteration %i: %f\" %(i, cost))\n",
    "        if  i % print_after == 0:\n",
    "            costs.append(cost)\n",
    "            \n",
    "    # plot the cost\n",
    "    plt.plot(np.squeeze(costs))\n",
    "    plt.ylabel('cost')\n",
    "    plt.xlabel('iterations (per '+str(print_after)+')')\n",
    "    plt.title(\"Learning rate =\" + str(learning_rate))\n",
    "    plt.show()\n",
    "    \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(Y,Yhat,Set):\n",
    "    spos=0\n",
    "    \n",
    "    for i in range(Y.shape[1]): \n",
    "        if Y[0,i]==1 and Yhat[0,i]==1:\n",
    "            spos = spos+1\n",
    "            \n",
    "    p = spos /np.sum(Yhat == 1)\n",
    "    r = spos/ np.sum( Y == 1)\n",
    "    acc = np.mean(Y == Yhat)\n",
    "    f1score = 2*p*r/(p+r)\n",
    "    \n",
    "    #print(Set+\" :       \"+str(p) + \"  \"+str(r)+\"  \"+str(f1score)+\"  \"+str(acc))\n",
    "    data = [{'Precision': p, 'Recall': r, 'Accuracy': acc,'F-score': f1score}] \n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    display(df)\n",
    "    error = (1-acc)*100\n",
    "    print(Set+\" :       \"+'%0.3f'%error+\" %\" +'\\t'+str(f1score))\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after iteration 0: 0.722761\n",
      "Cost after iteration 50: 0.680181\n",
      "Cost after iteration 100: 0.629324\n",
      "Cost after iteration 150: 0.566817\n",
      "Cost after iteration 200: 0.509269\n",
      "Cost after iteration 250: 0.454211\n",
      "Cost after iteration 300: 0.404124\n",
      "Cost after iteration 350: 0.360104\n",
      "Cost after iteration 400: 0.322703\n",
      "Cost after iteration 450: 0.292523\n",
      "Cost after iteration 500: 0.269336\n",
      "Cost after iteration 550: 0.253660\n",
      "Cost after iteration 600: 0.244067\n",
      "Cost after iteration 650: 0.237328\n",
      "Cost after iteration 700: 0.231895\n",
      "Cost after iteration 750: 0.229325\n",
      "Cost after iteration 800: 0.228874\n",
      "Cost after iteration 850: 0.228144\n",
      "Cost after iteration 900: 0.228984\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F-score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.92517</td>\n",
       "      <td>0.931507</td>\n",
       "      <td>0.928082</td>\n",
       "      <td>0.928328</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Precision    Recall  Accuracy   F-score\n",
       "0    0.92517  0.931507  0.928082  0.928328"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test  :       7.192 %\t0.9283276450511946\n",
      "Seed of initialization : 3\n"
     ]
    }
   ],
   "source": [
    "global dropout_cache\n",
    "global keep_prob\n",
    "global lambd\n",
    "\n",
    "np.random.seed(3)\n",
    "keep_prob=1\n",
    "lambd = 5e-2\n",
    "decay_rate=0\n",
    "\n",
    "p = model(train_X, train_Y, layers_dims = [10,64,32,16,8,4,1], epocs =901, \n",
    "                           learning_rate0 = 0.00009,  beta1 = 0.9, beta2 = 0.9,  epsilon = 1e-8, \n",
    "                           print_after = 50)\n",
    "\n",
    "def predict(X,p):\n",
    "    keep_prob=1\n",
    "    AL = forwardprop(X, p)[0]\n",
    "    Y_prediction = AL\n",
    "    for i in range(AL.shape[1]):\n",
    "          Y_prediction[0, i] = 1 if AL[0, i] > 0.5 else 0\n",
    "   \n",
    "    return Y_prediction \n",
    "\n",
    "test_Yhat = predict(test_X,p)\n",
    "train_Yhat = predict(train_X,p)\n",
    "\n",
    "evaluate(test_Y,test_Yhat,\"Test \")\n",
    "\n",
    "print(\"Seed of initialization : \"+str(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
